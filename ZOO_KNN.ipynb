{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb5bd414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edc33def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal name</th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airborne</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antelope</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>wallaby</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>wasp</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>wolf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>worm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>wren</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    animal name  hair  feathers  eggs  milk  airborne  aquatic  predator  \\\n",
       "0      aardvark     1         0     0     1         0        0         1   \n",
       "1      antelope     1         0     0     1         0        0         0   \n",
       "2          bass     0         0     1     0         0        1         1   \n",
       "3          bear     1         0     0     1         0        0         1   \n",
       "4          boar     1         0     0     1         0        0         1   \n",
       "..          ...   ...       ...   ...   ...       ...      ...       ...   \n",
       "96      wallaby     1         0     0     1         0        0         0   \n",
       "97         wasp     1         0     1     0         1        0         0   \n",
       "98         wolf     1         0     0     1         0        0         1   \n",
       "99         worm     0         0     1     0         0        0         0   \n",
       "100        wren     0         1     1     0         1        0         0   \n",
       "\n",
       "     toothed  backbone  breathes  venomous  fins  legs  tail  domestic  \\\n",
       "0          1         1         1         0     0     4     0         0   \n",
       "1          1         1         1         0     0     4     1         0   \n",
       "2          1         1         0         0     1     0     1         0   \n",
       "3          1         1         1         0     0     4     0         0   \n",
       "4          1         1         1         0     0     4     1         0   \n",
       "..       ...       ...       ...       ...   ...   ...   ...       ...   \n",
       "96         1         1         1         0     0     2     1         0   \n",
       "97         0         0         1         1     0     6     0         0   \n",
       "98         1         1         1         0     0     4     1         0   \n",
       "99         0         0         1         0     0     0     0         0   \n",
       "100        0         1         1         0     0     2     1         0   \n",
       "\n",
       "     catsize  type  \n",
       "0          1     1  \n",
       "1          1     1  \n",
       "2          0     4  \n",
       "3          1     1  \n",
       "4          1     1  \n",
       "..       ...   ...  \n",
       "96         1     1  \n",
       "97         0     6  \n",
       "98         1     1  \n",
       "99         0     7  \n",
       "100        0     2  \n",
       "\n",
       "[101 rows x 18 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoo = pd.read_csv(\"zoo.csv\")\n",
    "zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d3f2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoo.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40e8d064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, 1, 1, 1, 1, 4, 4, 1, 1, 2, 4, 7, 7, 7, 2, 1, 4, 1, 2, 2,\n",
       "       1, 2, 6, 5, 5, 1, 1, 1, 6, 1, 1, 2, 4, 1, 1, 2, 4, 6, 6, 2, 6, 2,\n",
       "       1, 1, 7, 1, 1, 1, 1, 6, 5, 7, 1, 1, 2, 2, 2, 2, 4, 4, 3, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 7, 4, 1, 1, 3, 7, 2, 2, 3, 7, 4, 2, 1, 7, 4, 2,\n",
       "       6, 5, 3, 3, 4, 1, 1, 2, 1, 6, 1, 7, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = zoo.values\n",
    "x = array[:,1:-1]\n",
    "y = array[:,-1]\n",
    "y=y.astype('int')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "245e06fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    41\n",
       "2    20\n",
       "4    13\n",
       "7    10\n",
       "6     8\n",
       "3     5\n",
       "5     4\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoo[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79ed5f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,shuffle=True,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "955b98fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387096774193549"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "391053a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.67      1.00      0.80         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.61      0.63      0.60        31\n",
      "weighted avg       0.84      0.84      0.83        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2419efd",
   "metadata": {},
   "source": [
    "# Visualizing the CV result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96fbbafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k value =  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      0.50      0.67         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.97        31\n",
      "   macro avg       0.86      0.79      0.81        31\n",
      "weighted avg       1.00      0.97      0.98        31\n",
      "\n",
      "k value =  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.88      0.94        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.67      1.00      0.80         4\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94        31\n",
      "   macro avg       0.94      0.98      0.96        31\n",
      "weighted avg       0.96      0.94      0.94        31\n",
      "\n",
      "k value =  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.67      1.00      0.80         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.61      0.63      0.60        31\n",
      "weighted avg       0.84      0.84      0.83        31\n",
      "\n",
      "k value =  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.45      0.55      0.49        31\n",
      "weighted avg       0.76      0.81      0.77        31\n",
      "\n",
      "k value =  9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.52      0.65      0.57        31\n",
      "weighted avg       0.73      0.81      0.76        31\n",
      "\n",
      "k value =  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.52      0.65      0.57        31\n",
      "weighted avg       0.73      0.81      0.76        31\n",
      "\n",
      "k value =  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.52      0.65      0.57        31\n",
      "weighted avg       0.73      0.81      0.76        31\n",
      "\n",
      "k value =  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.52      0.65      0.57        31\n",
      "weighted avg       0.73      0.81      0.76        31\n",
      "\n",
      "k value =  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.52      0.65      0.57        31\n",
      "weighted avg       0.73      0.81      0.76        31\n",
      "\n",
      "k value =  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.52      0.65      0.57        31\n",
      "weighted avg       0.73      0.81      0.76        31\n",
      "\n",
      "k value =  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.39      0.48      0.42        31\n",
      "weighted avg       0.61      0.74      0.67        31\n",
      "\n",
      "k value =  23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.39      0.48      0.42        31\n",
      "weighted avg       0.61      0.74      0.67        31\n",
      "\n",
      "k value =  25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       0.80      1.00      0.89         4\n",
      "           4       0.67      1.00      0.80         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.37      0.48      0.42        31\n",
      "weighted avg       0.60      0.74      0.66        31\n",
      "\n",
      "k value =  27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       0.44      1.00      0.62         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.20      0.31      0.24        31\n",
      "weighted avg       0.47      0.61      0.52        31\n",
      "\n",
      "k value =  29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       0.44      1.00      0.62         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.20      0.31      0.24        31\n",
      "weighted avg       0.47      0.61      0.52        31\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k value =  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       0.36      1.00      0.53         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.19      0.31      0.22        31\n",
      "weighted avg       0.46      0.61      0.51        31\n",
      "\n",
      "k value =  33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       0.36      1.00      0.53         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.19      0.31      0.22        31\n",
      "weighted avg       0.46      0.61      0.51        31\n",
      "\n",
      "k value =  35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       0.36      1.00      0.53         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.19      0.31      0.22        31\n",
      "weighted avg       0.46      0.61      0.51        31\n",
      "\n",
      "k value =  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       0.36      1.00      0.53         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.19      0.31      0.22        31\n",
      "weighted avg       0.46      0.61      0.51        31\n",
      "\n",
      "k value =  39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.88      0.81        17\n",
      "           2       0.36      1.00      0.53         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.19      0.31      0.22        31\n",
      "weighted avg       0.46      0.61      0.51        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "k_range = [2*i+1 for i in range(0,20)]\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn,x_train , y_train, cv=10)\n",
    "    k_scores.append(scores.mean())\n",
    "    print(\"k value = \",k)\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    print(classification_report(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60f3b966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(k_range, k_scores)\n",
    "plt.plot(k_range, k_scores, color = \"green\")\n",
    "plt.xlabel('value of K for KNN')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.xticks(k_range)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65d31de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1e66909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_range[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "634e4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      0.50      0.67         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.97        31\n",
      "   macro avg       0.86      0.79      0.81        31\n",
      "weighted avg       1.00      0.97      0.98        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy_score(pred,y_test)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689439e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
